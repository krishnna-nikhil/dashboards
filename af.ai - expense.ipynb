{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f67e759f-b4af-4450-b037-0f7ecb7fc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the Excel file\n",
    "file_path = \"/Users/devnikhil/Downloads/Feb _ March _ April _  Operation Master Sheet(Expenses )-2.xlsx\"\n",
    "\n",
    "# Load the Excel file into a DataFrame\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f2910ac-3fdd-4d1c-80ec-dd3956668ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 734 entries, 0 to 733\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   Date          734 non-null    datetime64[ns]\n",
      " 1   City Name     734 non-null    object        \n",
      " 2   AF Ops Name   734 non-null    object        \n",
      " 3   Department    734 non-null    object        \n",
      " 4   Category      734 non-null    object        \n",
      " 5   Amount        734 non-null    object        \n",
      " 6   Project       733 non-null    object        \n",
      " 7   Document No.  720 non-null    object        \n",
      " 8   Payee Name    708 non-null    object        \n",
      " 9   Narration     701 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 57.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdff12f9-71a8-4225-85f1-6d9f93a8643e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Names in DataFrame:\n",
      "Index(['Date', 'City Name', 'AF Ops Name', 'Department', 'Category', 'Amount',\n",
      "       'Project', 'Document No.', 'Payee Name', 'Narration'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print all column names to check for discrepancies\n",
    "print(\"Column Names in DataFrame:\")\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ed4ec42-79cc-4b4b-94ae-9c4f5b88f8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Dates:\n",
      "<DatetimeArray>\n",
      "['2025-05-01 00:00:00', '2025-05-02 00:00:00', '2025-05-03 00:00:00',\n",
      " '2025-05-04 00:00:00', '2025-05-05 00:00:00', '2025-05-06 00:00:00',\n",
      " '2025-05-07 00:00:00', '2025-05-08 00:00:00', '2025-05-09 00:00:00',\n",
      " '2025-05-10 00:00:00', '2025-05-11 00:00:00', '2025-05-12 00:00:00',\n",
      " '2025-05-13 00:00:00', '2025-05-14 00:00:00', '2025-05-15 00:00:00',\n",
      " '2025-05-16 00:00:00', '2025-05-17 00:00:00', '2025-05-18 00:00:00',\n",
      " '2025-05-19 00:00:00', '2025-05-20 00:00:00', '2025-05-22 00:00:00',\n",
      " '2025-05-23 00:00:00', '2025-05-24 00:00:00', '2025-05-25 00:00:00',\n",
      " '2025-05-26 00:00:00', '2025-05-27 00:00:00', '2025-05-28 00:00:00',\n",
      " '2025-05-29 00:00:00', '2025-05-30 00:00:00']\n",
      "Length: 29, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Strip whitespace from all column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Now, retrieve unique dates from the cleaned \"Date\" column\n",
    "unique_dates = df['Date'].unique()\n",
    "\n",
    "# Print unique dates\n",
    "print(\"Unique Dates:\")\n",
    "print(unique_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5a1fe76-c968-4525-83d2-952efec130c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date-wise Expense:\n",
      "         Date        Amount\n",
      "0  2025-05-01  14193.260000\n",
      "1  2025-05-02  13550.000000\n",
      "2  2025-05-03   4455.180000\n",
      "3  2025-05-04   8428.000000\n",
      "4  2025-05-05  50893.000000\n",
      "5  2025-05-06   6406.340000\n",
      "6  2025-05-07  10793.090000\n",
      "7  2025-05-08  12281.410000\n",
      "8  2025-05-09  13894.420000\n",
      "9  2025-05-10  28791.940000\n",
      "10 2025-05-11  89037.010000\n",
      "11 2025-05-12  17649.710000\n",
      "12 2025-05-13  19508.320000\n",
      "13 2025-05-14  19532.780000\n",
      "14 2025-05-15  15787.680000\n",
      "15 2025-05-16  14440.730000\n",
      "16 2025-05-17  20253.000000\n",
      "17 2025-05-18  26246.000000\n",
      "18 2025-05-19  20694.040000\n",
      "19 2025-05-20  22804.362298\n",
      "20 2025-05-22  75153.830000\n",
      "21 2025-05-23  25577.990000\n",
      "22 2025-05-24  20614.425316\n",
      "23 2025-05-25  16040.000000\n",
      "24 2025-05-26  48719.460000\n",
      "25 2025-05-27  15450.100000\n",
      "26 2025-05-28  29472.100000\n",
      "27 2025-05-29   6750.100000\n",
      "28 2025-05-30  16581.643486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Parse dates\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d.%m.%Y', errors='coerce')\n",
    "\n",
    "# Clean the 'Amount' column\n",
    "df['Amount'] = (\n",
    "    df['Amount']\n",
    "    .astype(str)\n",
    "    .str.replace('â‚¹', '', regex=False)\n",
    "    .str.replace('?', '', regex=False)\n",
    "    .str.replace(',', '')\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "# Convert to numeric, forcing errors to NaN\n",
    "df['Amount'] = pd.to_numeric(df['Amount'], errors='coerce')\n",
    "\n",
    "# Drop rows where Amount is NaN (could also fill with 0 if needed)\n",
    "df = df.dropna(subset=['Amount'])\n",
    "\n",
    "# Group by date and sum\n",
    "date_wise_expense = df.groupby('Date')['Amount'].sum().reset_index()\n",
    "\n",
    "# Display results\n",
    "print(\"Date-wise Expense:\")\n",
    "print(date_wise_expense)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f873b8-4ee8-407c-b1f7-2b30e1489239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardized Unique Regions:\n",
      "['hyderabad', 'bombay', 'hyderabad dc', 'mumbai vashi dc', 'hyderabad dc (warehouse)', 'mumbai dc', 'mumabi dc', 'garbage clearence', 'manpower', 'delhi dc (warehouse)', 'mumbai', 'mumbai vashi dc (warehouse)']\n"
     ]
    }
   ],
   "source": [
    "# Convert the 'Region' column to lowercase\n",
    "df['City Name'] = df['City Name'].str.lower()\n",
    "\n",
    "# Get unique regions after standardization\n",
    "unique_regions_standardized = df['City Name'].unique()\n",
    "\n",
    "# Convert to a list for easier reading\n",
    "unique_regions_standardized_list = unique_regions_standardized.tolist()\n",
    "\n",
    "# Print the standardized unique regions\n",
    "print(\"Standardized Unique Regions:\")\n",
    "print(unique_regions_standardized_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b0a5e39-d5a1-4e79-9260-6b0f93239510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Amount by Region:\n",
      "                      City Name         Amount\n",
      "0                        bombay    1500.000000\n",
      "1          delhi dc (warehouse)   17826.837989\n",
      "2             garbage clearence    3000.000000\n",
      "3                     hyderabad   39126.440000\n",
      "4                  hyderabad dc    2693.000000\n",
      "5      hyderabad dc (warehouse)  445493.643111\n",
      "6                      manpower    2800.000000\n",
      "7                     mumabi dc    5970.000000\n",
      "8                        mumbai   64840.000000\n",
      "9                     mumbai dc   96800.000000\n",
      "10              mumbai vashi dc    1500.000000\n",
      "11  mumbai vashi dc (warehouse)    2450.000000\n"
     ]
    }
   ],
   "source": [
    "# Total amount by Region\n",
    "total_by_region = df.groupby('City Name')['Amount'].sum().reset_index()\n",
    "print(\"Total Amount by Region:\")\n",
    "print(total_by_region)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "424f0ff2-3589-4b49-8fd3-ffd579c54647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Amount by Purpose:\n",
      "            Category         Amount\n",
      "0              admin    2610.000000\n",
      "1             lables   35014.168300\n",
      "2           logistic   88804.800000\n",
      "3          logistics  246645.783305\n",
      "4           manpower  155781.626697\n",
      "5            packing    5963.000000\n",
      "6   packing material   80211.100000\n",
      "7               rent   22934.189950\n",
      "8           stickers    3996.080000\n",
      "9            storage   23329.000000\n",
      "10        supervisor   18710.172848\n"
     ]
    }
   ],
   "source": [
    "# Total amount by Purpose (Product)\n",
    "df['Category'] = df['Category'].str.lower().str.strip()\n",
    "total_by_purpose = df.groupby('Category')['Amount'].sum().reset_index()\n",
    "print(\"\\nTotal Amount by Purpose:\")\n",
    "print(total_by_purpose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25ced65a-7aeb-4aed-8fa4-608174e7f60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Amount by Department:\n",
      "    Department         Amount\n",
      "0   opeartions  144870.067614\n",
      "1   operations  465929.853486\n",
      "2  procurement   73200.000000\n"
     ]
    }
   ],
   "source": [
    "df['Department'] = df['Department'].str.lower().str.strip()\n",
    "total_by_department = df.groupby('Department')['Amount'].sum().reset_index()\n",
    "print(\"\\nTotal Amount by Department:\")\n",
    "print(total_by_department)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e76290ff-8423-4e2e-8ca9-149aae7bbc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Amount by Purpose:\n",
      "                   Project         Amount\n",
      "0         avacado & dragon    4040.000000\n",
      "1                  avacodo    1380.000000\n",
      "2                blueberry    8351.892516\n",
      "3             dragon fruit  650743.681125\n",
      "4  dragon fruit 20 pcs box      32.309470\n",
      "5   dragon fruit 22 pc box       0.000000\n",
      "6       imported blueberry     223.200000\n",
      "7         indian blueberry    1082.000000\n",
      "8                raspberry   17826.837989\n"
     ]
    }
   ],
   "source": [
    "df['Project'] = df['Project'].str.lower().str.strip()\n",
    "total_by_purpose = df.groupby('Project')['Amount'].sum().reset_index()\n",
    "print(\"\\nTotal Amount by Purpose:\")\n",
    "print(total_by_purpose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6c69e6a3-3783-4ca6-98df-32f2fadab1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: Amount, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'YourDataFrame' with the name of your DataFrame\n",
    "strawberry_products = ['STARWBERRY PCK PC', 'Strawberry', 'Strawberry Punnet PKD PC']\n",
    "\n",
    "# Filter and calculate day-wise totals for the specified products\n",
    "day_wise_totals = df[df['Project'].isin(strawberry_products)].groupby('Date')['Amount'].sum()\n",
    "\n",
    "# Display the result\n",
    "print(day_wise_totals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b529808e-3b4b-4530-aad9-083821c210bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /Users/devnikhil/Downloads/expenses_maymonth.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate grouped summaries\n",
    "total_by_region = df.groupby('City Name')['Amount'].sum().reset_index()\n",
    "total_by_purpose_category = df.groupby('Category')['Amount'].sum().reset_index()\n",
    "total_by_department = df.groupby('Department')['Amount'].sum().reset_index()\n",
    "total_by_purpose_project = df.groupby('Project')['Amount'].sum().reset_index()\n",
    "\n",
    "# Define the output file path\n",
    "output_file = '/Users/devnikhil/Downloads/expenses_maymonth.xlsx'\n",
    "\n",
    "# Save results to separate sheets in the same Excel file\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    total_by_region.to_excel(writer, sheet_name='Total by Region', index=False)\n",
    "    total_by_purpose_category.to_excel(writer, sheet_name='Total by Category', index=False)\n",
    "    total_by_department.to_excel(writer, sheet_name='Total by Department', index=False)\n",
    "    total_by_purpose_project.to_excel(writer, sheet_name='Total by Project', index=False)\n",
    "\n",
    "print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb1595-181c-4334-80cd-cb34ff04f2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423bef50-edc1-4229-b39e-326765185126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
